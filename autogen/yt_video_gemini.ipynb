{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harjeet88/agentic_ai/blob/main/autogen/yt_video_gemini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q autogen-agentchat\n",
        "!pip install -q autogen-ext[openai]\n",
        "!pip install -q python-dotenv         # Optional, for managing API keys\n",
        "#pip install -q elevenlabs\n",
        "!pip install -q requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcqq9cIDR8kx",
        "outputId": "76f91b1c-9bce-4e42-8a0f-2c531da70bc2"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autogen-agentchat\n",
            "  Downloading autogen_agentchat-0.6.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting autogen-core==0.6.1 (from autogen-agentchat)\n",
            "  Downloading autogen_core-0.6.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting jsonref~=1.1.0 (from autogen-core==0.6.1->autogen-agentchat)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting opentelemetry-api>=1.27.0 (from autogen-core==0.6.1->autogen-agentchat)\n",
            "  Downloading opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pillow>=11.0.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.6.1->autogen-agentchat) (11.2.1)\n",
            "Requirement already satisfied: protobuf~=5.29.3 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.6.1->autogen-agentchat) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.10.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.6.1->autogen-agentchat) (2.11.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.6.1->autogen-agentchat) (4.14.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.27.0->autogen-core==0.6.1->autogen-agentchat) (8.7.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.6.1->autogen-agentchat) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.6.1->autogen-agentchat) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.6.1->autogen-agentchat) (0.4.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.27.0->autogen-core==0.6.1->autogen-agentchat) (3.23.0)\n",
            "Downloading autogen_agentchat-0.6.1-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.2/108.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogen_core-0.6.1-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.3/97.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jsonref, opentelemetry-api, autogen-core, autogen-agentchat\n",
            "Successfully installed autogen-agentchat-0.6.1 autogen-core-0.6.1 jsonref-1.1.0 opentelemetry-api-1.34.1\n",
            "Collecting autogen-ext[openai]\n",
            "  Downloading autogen_ext-0.6.1-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: autogen-core==0.6.1 in /usr/local/lib/python3.11/dist-packages (from autogen-ext[openai]) (0.6.1)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.11/dist-packages (from autogen-ext[openai]) (24.1.0)\n",
            "Requirement already satisfied: openai>=1.66.5 in /usr/local/lib/python3.11/dist-packages (from autogen-ext[openai]) (1.91.0)\n",
            "Requirement already satisfied: tiktoken>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from autogen-ext[openai]) (0.9.0)\n",
            "Requirement already satisfied: jsonref~=1.1.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.6.1->autogen-ext[openai]) (1.1.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.27.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.6.1->autogen-ext[openai]) (1.34.1)\n",
            "Requirement already satisfied: pillow>=11.0.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.6.1->autogen-ext[openai]) (11.2.1)\n",
            "Requirement already satisfied: protobuf~=5.29.3 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.6.1->autogen-ext[openai]) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.10.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.6.1->autogen-ext[openai]) (2.11.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.6.1->autogen-ext[openai]) (4.14.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.66.5->autogen-ext[openai]) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.66.5->autogen-ext[openai]) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.66.5->autogen-ext[openai]) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.66.5->autogen-ext[openai]) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.66.5->autogen-ext[openai]) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai>=1.66.5->autogen-ext[openai]) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.8.0->autogen-ext[openai]) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.8.0->autogen-ext[openai]) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai>=1.66.5->autogen-ext[openai]) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.66.5->autogen-ext[openai]) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.66.5->autogen-ext[openai]) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.66.5->autogen-ext[openai]) (0.16.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.27.0->autogen-core==0.6.1->autogen-ext[openai]) (8.7.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.6.1->autogen-ext[openai]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.6.1->autogen-ext[openai]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.6.1->autogen-ext[openai]) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken>=0.8.0->autogen-ext[openai]) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken>=0.8.0->autogen-ext[openai]) (2.4.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.27.0->autogen-core==0.6.1->autogen-ext[openai]) (3.23.0)\n",
            "Downloading autogen_ext-0.6.1-py3-none-any.whl (306 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.4/306.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: autogen-ext\n",
            "Successfully installed autogen-ext-0.6.1\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv"
      ],
      "metadata": {
        "id": "aPKAipc1SKt3"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "GEMINI_API_KEY=GOOGLE_API_KEY"
      ],
      "metadata": {
        "id": "sFXuuVQ_Sg-I"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "MODEL_NAME = \"gemini-1.5-flash-latest\" # Using the latest flash model\n",
        "gemini=MODEL_NAME"
      ],
      "metadata": {
        "id": "xVIHjbT-T6XB"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import autogen\n",
        "from autogen.agentchat.contrib.gpt_assistant_agent import GPTAssistantAgent\n",
        "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent"
      ],
      "metadata": {
        "id": "NpV6u4UcTHSB"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_config = [\n",
        "    {\n",
        "        \"model\": gemini,\n",
        "        \"api_key\": GOOGLE_API_KEY,\n",
        "        \"api_type\": \"google\"\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "4SQQmXspT0fJ"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assitant_writer='''\n",
        "        You are a creative assistant tasked with writing a script for a short video.\n",
        "        The script should consist of captions designed to be displayed on-screen, with the following guidelines:\n",
        "            1.\tEach caption must be short and impactful (no more than 8 words) to avoid overwhelming the viewer.\n",
        "            2.\tThe script should have exactly 5 captions, each representing a key moment in the story.\n",
        "            3.\tThe flow of captions must feel natural, like a compelling voiceover guiding the viewer through the narrative.\n",
        "            4.\tAlways start with a question or a statement that keeps the viewer wanting to know more.\n",
        "            5.  You must also include the topic and takeaway in your response.\n",
        "            6.  The caption values must ONLY include the captions, no additional meta data or information.\n",
        "\n",
        "            Output your response in the following JSON format:\n",
        "            {\n",
        "                \"topic\": \"topic\",\n",
        "                \"takeaway\": \"takeaway\",\n",
        "                \"captions\": [\n",
        "                    \"caption1\",\n",
        "                    \"caption2\",\n",
        "                    \"caption3\",\n",
        "                    \"caption4\",\n",
        "                    \"caption5\"\n",
        "                ]\n",
        "            }\n",
        "    '''"
      ],
      "metadata": {
        "id": "4ji3uuR8Svbi"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_script_writer(config_list_gemini):\n",
        "    return autogen.AssistantAgent(\n",
        "        name=\"script_writer\",\n",
        "        system_message=assitant_writer,\n",
        "        llm_config={\n",
        "        \"cache_seed\": 41,\n",
        "        \"config_list\": config_list_gemini,\n",
        "        \"seed\": 42\n",
        "    },\n",
        "        code_execution_config=False,\n",
        "    )"
      ],
      "metadata": {
        "id": "BgOG682QTpGC"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "script_writer = create_script_writer(llm_config)\n"
      ],
      "metadata": {
        "id": "kTXV5BonSbOT"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i_yAlwwES2ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Tx6OJqsVL3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6O0c2vJaVL1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iiSIywhVVLyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EuRCsmukVLvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "import wave\n"
      ],
      "metadata": {
        "id": "D8jCewtfVLr5"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the wave file to save the output:\n",
        "def wave_file(filename, pcm, channels=1, rate=24000, sample_width=2):\n",
        "   with wave.open(filename, \"wb\") as wf:\n",
        "      wf.setnchannels(channels)\n",
        "      wf.setsampwidth(sample_width)\n",
        "      wf.setframerate(rate)\n",
        "      wf.writeframes(pcm)\n"
      ],
      "metadata": {
        "id": "ykX9MPDCVLlK"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "pxFDFnpNVR3F"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.models.generate_content(\n",
        "   model=\"gemini-2.5-flash-preview-tts\",\n",
        "   contents=\"Say cheerfully: Have a wonderful day!\",\n",
        "   config=types.GenerateContentConfig(\n",
        "      response_modalities=[\"AUDIO\"],\n",
        "      speech_config=types.SpeechConfig(\n",
        "         voice_config=types.VoiceConfig(\n",
        "            prebuilt_voice_config=types.PrebuiltVoiceConfig(\n",
        "               voice_name='Kore',\n",
        "            )\n",
        "         )\n",
        "      ),\n",
        "   )\n",
        ")\n"
      ],
      "metadata": {
        "id": "ggCLW7iJVUKi"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcript = client.models.generate_content(\n",
        "   model=\"gemini-2.0-flash\",\n",
        "   contents=\"\"\"Generate a short transcript around 100 words that reads\n",
        "            like it is a youtube short between two excited persons who are couple.\n",
        "            names are Dr. Anya and Liam.\"\"\").text\n",
        "\n",
        "response = client.models.generate_content(\n",
        "   model=\"gemini-2.5-flash-preview-tts\",\n",
        "   contents=transcript,\n",
        "   config=types.GenerateContentConfig(\n",
        "      response_modalities=[\"AUDIO\"],\n",
        "      speech_config=types.SpeechConfig(\n",
        "         multi_speaker_voice_config=types.MultiSpeakerVoiceConfig(\n",
        "            speaker_voice_configs=[\n",
        "               types.SpeakerVoiceConfig(\n",
        "                  speaker='Dr. Anya',\n",
        "                  voice_config=types.VoiceConfig(\n",
        "                     prebuilt_voice_config=types.PrebuiltVoiceConfig(\n",
        "                        voice_name='Kore',\n",
        "                     )\n",
        "                  )\n",
        "               ),\n",
        "               types.SpeakerVoiceConfig(\n",
        "                  speaker='Liam',\n",
        "                  voice_config=types.VoiceConfig(\n",
        "                     prebuilt_voice_config=types.PrebuiltVoiceConfig(\n",
        "                        voice_name='Puck',\n",
        "                     )\n",
        "                  )\n",
        "               ),\n",
        "            ]\n",
        "         )\n",
        "      )\n",
        "   )\n",
        ")"
      ],
      "metadata": {
        "id": "XHN0ZLNQVy9C"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = response.candidates[0].content.parts[0].inline_data.data\n",
        "\n",
        "file_name='out.wav'\n",
        "wave_file(file_name, data) # Saves the file to current directory"
      ],
      "metadata": {
        "id": "Xyb-dwBPVZno"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5KI6DASdXk0P"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}