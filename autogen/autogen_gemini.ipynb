{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harjeet88/agentic_ai/blob/main/autogen/autogen_gemini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sHsPXZn7BUJx",
        "outputId": "2160bed4-2828-44f6-9630-c37f9f6fc5d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/microsoft/autogen.git@v0.2.25\n",
            "  Cloning https://github.com/microsoft/autogen.git (to revision v0.2.25) to /tmp/pip-req-build-hax5uuwi\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/microsoft/autogen.git /tmp/pip-req-build-hax5uuwi\n",
            "  Running command git checkout -q 4ab8a884870f4aeafe3587c56169bb094061af5b\n",
            "  Encountered 1 file(s) that should have been pointers, but weren't:\n",
            "        website/static/img/gallery/autotx.png\n",
            "  Resolved https://github.com/microsoft/autogen.git to commit 4ab8a884870f4aeafe3587c56169bb094061af5b\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: openai>=1.3 in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.2.25) (1.91.0)\n",
            "Collecting diskcache (from pyautogen==0.2.25)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.2.25) (3.1.0)\n",
            "Collecting flaml (from pyautogen==0.2.25)\n",
            "  Downloading FLAML-2.3.5-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting numpy<2,>=1.17.0 (from pyautogen==0.2.25)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv (from pyautogen==0.2.25)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.2.25) (0.9.0)\n",
            "Requirement already satisfied: pydantic!=2.6.0,<3,>=1.10 in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.2.25) (2.11.7)\n",
            "Collecting docker (from pyautogen==0.2.25)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.3->pyautogen==0.2.25) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.3->pyautogen==0.2.25) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.3->pyautogen==0.2.25) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.3->pyautogen==0.2.25) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.3->pyautogen==0.2.25) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai>=1.3->pyautogen==0.2.25) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai>=1.3->pyautogen==0.2.25) (4.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen==0.2.25) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen==0.2.25) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen==0.2.25) (0.4.1)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from docker->pyautogen==0.2.25) (2.32.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker->pyautogen==0.2.25) (2.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->pyautogen==0.2.25) (2024.11.6)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen==0.2.25) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.3->pyautogen==0.2.25) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.3->pyautogen==0.2.25) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3->pyautogen==0.2.25) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->docker->pyautogen==0.2.25) (3.4.2)\n",
            "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading FLAML-2.3.5-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Building wheels for collected packages: pyautogen\n",
            "  Building wheel for pyautogen (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyautogen: filename=pyautogen-0.2.25-py3-none-any.whl size=257234 sha256=c78ddec7d7d9a8fe731ebacea7ddbda9607853f372e5d2ecd9dc9fff68d7921b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-a6t_d7ku/wheels/9c/f5/06/fc5e348944b6b822424c6cb5d6bda8a51a21c8abdf855477de\n",
            "Successfully built pyautogen\n",
            "Installing collected packages: python-dotenv, numpy, diskcache, flaml, docker, pyautogen\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed diskcache-5.6.3 docker-7.1.0 flaml-2.3.5 numpy-1.26.4 pyautogen-0.2.25 python-dotenv-1.1.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "a71006f4cf6140d7bdb96003f90007e6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install git+https://github.com/microsoft/autogen.git@v0.2.25"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY= userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "gEoVTTjOqnfy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h_vnS4mdqoQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ts-3MihDCVYN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "api_key = GOOGLE_API_KEY\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input=\"\"\"\n",
        "use autogen to create an agentic AI solution in python. this solution should do following\n",
        "1. given a stock it should do fundamental analysis and explain if the stock is worth investment\n",
        "2. one of the agents should do technical analysis of stock to check various technical indicators like RSI, MCAD, elliot wave, 50 DMA, 200 DMA , super trend, price volume action and suggest wheather we should invest or not\n",
        "3. if the stock is worth investment, system should suggest what is right entry level and exit level for stock.\n",
        "generate python code for this which i can directly run in jupyter notebook.\n",
        "\"\"\"\n",
        "\n",
        "gemini=\"gemini-2.5-flash-lite-preview-06-17\""
      ],
      "metadata": {
        "id": "GAhSZiZF6I9Q"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0jw_zkVr63P2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tXJGPt7iFpBm",
        "outputId": "74e41634-f2e6-4177-b6f1-b9c5ffddca45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user_proxy (to assistant):\n",
            "\n",
            "\n",
            "use autogen to create an agentic AI solution in python. this solution should do following\n",
            "1. given a stock it should do fundamental analysis and explain if the stock is worth investment\n",
            "2. one of the agents should do technical analysis of stock to check various technical indicators like RSI, MCAD, elliot wave, 50 DMA, 200 DMA , super trend, price volume action and suggest wheather we should invest or not\n",
            "3. if the stock is worth investment, system should suggest what is right entry level and exit level for stock.\n",
            "generate python code for this which i can directly run in jupyter notebook.\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "assistant (to user_proxy):\n",
            "\n",
            "Here's a plan to create an agentic AI solution for stock analysis using Python and Autogen:\n",
            "\n",
            "**Plan:**\n",
            "\n",
            "1.  **Define Agent Roles:** We'll create three distinct agents:\n",
            "    *   **Fundamental Analyst:** This agent will focus on financial statements, company health, industry trends, and overall economic factors to determine if a stock is fundamentally sound.\n",
            "    *   **Technical Analyst:** This agent will analyze price charts, trading volumes, and various technical indicators (RSI, MACD, Moving Averages, etc.) to identify potential buy/sell signals and trading patterns.\n",
            "    *   **Investment Strategist (Orchestrator):** This agent will act as the orchestrator, taking the analysis from the other two agents and making a final recommendation on whether to invest, including entry and exit points.\n",
            "\n",
            "2.  **Select Libraries:** We'll need libraries for:\n",
            "    *   **Autogen:** For creating and managing the agents.\n",
            "    *   **yfinance:** To fetch historical stock data for technical analysis and some fundamental data.\n",
            "    *   **pandas:** For data manipulation.\n",
            "    *   **talib (or similar):** For calculating technical indicators. (Note: `talib` can be tricky to install. If installation is problematic, we can focus on more readily available indicators or mock some of the more complex ones for demonstration purposes. For this example, I'll assume `talib` is installable or we'll adapt if it's not.)\n",
            "    *   **requests/BeautifulSoup (optional):** For scraping more detailed fundamental data if `yfinance` isn't sufficient.\n",
            "\n",
            "3.  **Implement Agent Logic:**\n",
            "    *   **Fundamental Analyst:** This agent will need access to financial ratios (P/E, EPS, Debt-to-Equity), revenue growth, profit margins, and industry-specific metrics. For this example, we'll simulate some of this by using data available through `yfinance` and making educated assumptions or using simplified checks.\n",
            "    *   **Technical Analyst:** This agent will calculate and interpret indicators like RSI, MACD, and moving averages. It will also look at price-volume action.\n",
            "    *   **Investment Strategist:** This agent will receive reports from both analysts. It will weigh the fundamental and technical outlooks. If both are positive, it will suggest entry and exit points based on technical signals and the overall analysis.\n",
            "\n",
            "4.  **Structure the Code:** We'll set up a Python script that initializes the agents and then initiates a conversation between them.\n",
            "\n",
            "**Note on `talib` Installation:**\n",
            "`talib` can sometimes be challenging to install due to its C dependencies. If you encounter issues, you might need to install the TA-Lib library first on your system. For example, on Ubuntu:\n",
            "```bash\n",
            "sudo apt-get update\n",
            "sudo apt-get install -y libta-lib-dev\n",
            "pip install TA-Lib\n",
            "```\n",
            "If you're on macOS with Homebrew:\n",
            "```bash\n",
            "brew install ta-lib\n",
            "pip install TA-Lib\n",
            "```\n",
            "If `talib` installation remains an issue, we can adapt the technical analysis part to use simpler calculations or mock data for demonstration. For this code, I'll include `talib` and assume it's installed or the user can handle the installation.\n",
            "\n",
            "Let's begin with the Python code.\n",
            "\n",
            "```python\n",
            "# filename: stock_analysis_agents.py\n",
            "import autogen\n",
            "import yfinance as yf\n",
            "import pandas as pd\n",
            "import talib\n",
            "from autogen import GroupChat, GroupChatManager\n",
            "import os\n",
            "import json\n",
            "\n",
            "# --- Helper Functions ---\n",
            "\n",
            "def get_stock_data(ticker, period=\"1y\"):\n",
            "    \"\"\"Fetches historical stock data.\"\"\"\n",
            "    stock = yf.Ticker(ticker)\n",
            "    hist = stock.history(period=period)\n",
            "    return hist\n",
            "\n",
            "def get_company_info(ticker):\n",
            "    \"\"\"Fetches basic company information.\"\"\"\n",
            "    stock = yf.Ticker(ticker)\n",
            "    return stock.info\n",
            "\n",
            "# --- Agent Definitions ---\n",
            "\n",
            "# User Proxy Agent (to interact with the agents)\n",
            "user_proxy = autogen.UserProxyAgent(\n",
            "    name=\"User_Proxy\",\n",
            "    human_input_mode=\"NEVER\",  # Set to \"ALWAYS\" if you want to participate\n",
            "    code_execution_config={\"use_docker\": False},\n",
            "    is_termination_msg=lambda x: \"TERMINATE\" in x,\n",
            "    system_message=\"\"\"A proxy user that calls other agents to perform stock analysis.\n",
            "    You will be asked by the system to provide a stock ticker.\n",
            "    After the analysis is done, you will report the findings.\n",
            "    You will initiate the analysis by specifying the stock ticker and the task.\n",
            "    Example: \"Analyze stock AAPL for investment.\"\n",
            "    \"\"\"\n",
            ")\n",
            "\n",
            "# Fundamental Analyst Agent\n",
            "fundamental_analyst = autogen.AssistantAgent(\n",
            "    name=\"Fundamental_Analyst\",\n",
            "    llm_config={\"config_list\": [{\"model\": \"gpt-4o\", \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
            "    system_message=\"\"\"You are a Fundamental Analyst. Your task is to analyze a stock's fundamentals and determine if it's worth investing in based on financial health, industry trends, and economic outlook.\n",
            "    Provide a detailed explanation. If you find the stock fundamentally sound, say \"FUNDAMENTALLY SOUND\". Otherwise, say \"FUNDAMENTALLY WEAK\".\n",
            "    Provide a summary of your findings, including key metrics like P/E ratio, EPS, revenue growth, debt-to-equity, and industry outlook.\n",
            "    If you need to look up information, use the provided code interpreter.\n",
            "    When you are done, say \"FUNDAMENTAL ANALYSIS COMPLETE\".\n",
            "    \"\"\"\n",
            ")\n",
            "\n",
            "# Technical Analyst Agent\n",
            "technical_analyst = autogen.AssistantAgent(\n",
            "    name=\"Technical_Analyst\",\n",
            "    llm_config={\"config_list\": [{\"model\": \"gpt-4o\", \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
            "    system_message=\"\"\"You are a Technical Analyst. Your task is to analyze a stock's price action, volume, and technical indicators to suggest whether to invest.\n",
            "    Calculate and interpret the following:\n",
            "    1. Relative Strength Index (RSI): Overbought (>70), Oversold (<30), Neutral (30-70).\n",
            "    2. Moving Average Convergence Divergence (MACD): Crossovers and histogram.\n",
            "    3. Moving Averages: 50-day and 200-day (golden cross, death cross).\n",
            "    4. Price-Volume Action: Trends, breakouts, breakdowns.\n",
            "    (Note: Elliot Wave and Supertrend are complex and might require more specialized libraries or manual interpretation. For this demonstration, we will focus on RSI, MACD, and Moving Averages, and general price-volume action. If you need to execute code, use the provided interpreter.)\n",
            "\n",
            "    Provide a summary of your technical analysis and a recommendation: \"TECHNICALALLY GOOD\" or \"TECHNICALALLY WEAK\".\n",
            "    If you recommend investing, also suggest potential entry and exit levels based on your analysis.\n",
            "    When you are done, say \"TECHNICAL ANALYSIS COMPLETE\".\n",
            "    \"\"\"\n",
            ")\n",
            "\n",
            "# Investment Strategist Agent\n",
            "investment_strategist = autogen.AssistantAgent(\n",
            "    name=\"Investment_Strategist\",\n",
            "    llm_config={\"config_list\": [{\"model\": \"gpt-4o\", \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
            "    system_message=\"\"\"You are an Investment Strategist. Your role is to synthesize the fundamental and technical analyses to make a final investment recommendation.\n",
            "    Based on the reports from the Fundamental Analyst and Technical Analyst:\n",
            "    1. If both analyses are positive, recommend to invest. Provide a clear entry level (based on technicals) and an exit level (e.g., target price or stop-loss).\n",
            "    2. If one analysis is positive and the other is neutral or mixed, proceed with caution and recommend a smaller investment or wait for clearer signals.\n",
            "    3. If both analyses are negative, recommend against investing.\n",
            "    You will also provide a final summary of the overall investment case.\n",
            "    When you are done, say \"INVESTMENT RECOMMENDATION COMPLETE\".\n",
            "    \"\"\"\n",
            ")\n",
            "\n",
            "# --- Group Chat Setup ---\n",
            "\n",
            "# List of agents\n",
            "agents = [user_proxy, fundamental_analyst, technical_analyst, investment_strategist]\n",
            "\n",
            "# Group chat with a predefined order for simpler workflows\n",
            "# The user_proxy starts the conversation.\n",
            "# The user_proxy will then delegate to fundamental_analyst.\n",
            "# fundamental_analyst will respond and then delegate to technical_analyst.\n",
            "# technical_analyst will respond and then delegate to investment_strategist.\n",
            "# investment_strategist will then respond and the user_proxy will terminate.\n",
            "\n",
            "groupchat = GroupChat(\n",
            "    agents=agents,\n",
            "    messages=[],\n",
            "    max_round=20, # Increased rounds to allow for more complex interactions\n",
            "    speaker_selection_method=\"auto\", # Or \"round_robin\" for simpler control\n",
            ")\n",
            "\n",
            "manager = GroupChatManager(groupchat=groupchat, llm_config={\"config_list\": [{\"model\": \"gpt-4o\", \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]})\n",
            "\n",
            "# --- Execution ---\n",
            "\n",
            "# Define the stock ticker to analyze\n",
            "stock_ticker = \"AAPL\"  # Example stock\n",
            "\n",
            "# Initiate the conversation\n",
            "print(f\"Starting analysis for stock: {stock_ticker}\")\n",
            "user_proxy.initiate_chat(\n",
            "    manager,\n",
            "    message=f\"Please analyze stock {stock_ticker} for investment. Start with fundamental analysis.\"\n",
            ")\n",
            "\n",
            "# To get the final summary and recommendation from the Investment Strategist,\n",
            "# you would typically parse the messages in the group chat after the conversation ends.\n",
            "# For this example, we'll assume the last message from the Investment Strategist contains the summary.\n",
            "\n",
            "# You can retrieve the chat history like this:\n",
            "# chat_history = groupchat.messages\n",
            "# print(\"\\n--- Chat History ---\")\n",
            "# for msg in chat_history:\n",
            "#     print(f\"{msg['from']}: {msg['content']}\")\n",
            "\n",
            "# The user_proxy should have a final message indicating termination.\n",
            "# The output from the Investment Strategist will be within the chat history.\n",
            "\n",
            "print(\"\\n--- Analysis Complete ---\")\n",
            "print(f\"Please review the chat history above for the detailed analysis and investment recommendation for {stock_ticker}.\")\n",
            "print(\"The Investment Strategist's final recommendation should be clearly stated.\")\n",
            "\n",
            "# --- Example of how to access the final recommendation (manual parsing of history) ---\n",
            "# This part is illustrative. In a real application, you might want a more structured way\n",
            "# for the Investment Strategist to output its final conclusion.\n",
            "\n",
            "final_recommendation = None\n",
            "for msg in groupchat.messages:\n",
            "    if msg['from'] == 'Investment_Strategist':\n",
            "        if \"INVESTMENT RECOMMENDATION COMPLETE\" in msg['content']:\n",
            "            final_recommendation = msg['content']\n",
            "            break\n",
            "\n",
            "if final_recommendation:\n",
            "    print(\"\\n--- Final Investment Recommendation ---\")\n",
            "    print(final_recommendation)\n",
            "else:\n",
            "    print(\"\\nCould not find a clear final recommendation in the chat history.\")\n",
            "\n",
            "```\n",
            "\n",
            "**Explanation:**\n",
            "\n",
            "1.  **`user_proxy`**: This is your entry point. It's configured to not require human input (`human_input_mode=\"NEVER\"`) so the agents can converse autonomously. It's also set up to terminate the conversation when it sees \"TERMINATE\".\n",
            "2.  **`fundamental_analyst`**:\n",
            "    *   **System Message**: Clearly defines its role, what it should analyze, and what keywords to use for its output (`FUNDAMENTALLY SOUND`, `FUNDAMENTALLY WEAK`). It's instructed to use the code interpreter if needed.\n",
            "    *   **LLM Config**: Specifies which model to use (e.g., `gpt-4o`) and requires your OpenAI API key to be set as an environment variable `OPENAI_API_KEY`.\n",
            "3.  **`technical_analyst`**:\n",
            "    *   **System Message**: Details the technical indicators to consider (RSI, MACD, Moving Averages) and how to interpret them. It also mentions limitations (Elliot Wave, Supertrend) for this example. It uses similar output keywords (`TECHNICALALLY GOOD`, `TECHNICALALLY WEAK`) and entry/exit level suggestions.\n",
            "4.  **`investment_strategist`**:\n",
            "    *   **System Message**: This agent acts as the decision-maker. It takes inputs from the other two analysts and synthesizes them into a final recommendation, including entry/exit points, and provides an overall summary.\n",
            "5.  **`GroupChat` and `GroupChatManager`**:\n",
            "    *   We define a `GroupChat` that includes all our agents.\n",
            "    *   `speaker_selection_method=\"auto\"` tells Autogen to automatically decide who speaks next based on the conversation flow and agent system messages.\n",
            "    *   `max_round=20` is set to allow enough turns for the agents to complete their tasks.\n",
            "    *   The `GroupChatManager` orchestrates the conversation within the group.\n",
            "6.  **Execution Flow**:\n",
            "    *   The `user_proxy` initiates the chat with a message to the `manager`, specifying the stock ticker and task.\n",
            "    *   The `manager` then orchestrates the conversation, typically starting with the `fundamental_analyst`.\n",
            "    *   Each agent performs its task, communicates its findings to the next agent in the predefined logical flow (User -> Fundamental -> Technical -> Strategist), and signals completion.\n",
            "    *   The `Investment_Strategist` provides the final output.\n",
            "    *   The script then prints a message indicating the analysis is complete and attempts to extract and print the final recommendation from the chat history.\n",
            "\n",
            "**To Run This Code:**\n",
            "\n",
            "1.  **Install Libraries:**\n",
            "    ```bash\n",
            "    pip install autogen yfinance pandas openai\n",
            "    # For talib, follow instructions in the note above for your OS\n",
            "    # pip install TA-Lib\n",
            "    ```\n",
            "2.  **Set OpenAI API Key:** You need to have an OpenAI API key. Set it as an environment variable:\n",
            "    *   **Linux/macOS:** `export OPENAI_API_KEY='your-api-key'`\n",
            "    *   **Windows:** `$env:OPENAI_API_KEY='your-api-key'`\n",
            "    (Replace `'your-api-key'` with your actual key).\n",
            "3.  **Run in Jupyter Notebook:** Copy and paste the entire code block into a Jupyter Notebook cell and execute it.\n",
            "\n",
            "This setup provides a solid foundation for an agentic AI stock analysis solution. The agents' instructions can be further refined for more sophisticated analysis.\n",
            "\n",
            "TERMINATE\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-16-3986109824.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mchat_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mconvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mtotal_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"CHAT REF: {chat_id}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 1"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import autogen\n",
        "from autogen import AssistantAgent, UserProxyAgent\n",
        "from autogen.code_utils import  infer_lang\n",
        "from google.colab import userdata\n",
        "\n",
        "# Retrieve your API key securely stored as a secret\n",
        "#api_key= userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "if not api_key:\n",
        "  raise ValueError(f\"KEY: '{api_key}' is invalid\")\n",
        "\n",
        "MAX_USER_REPLIES=5\n",
        "INPUT_START_MESSAGE = input\n",
        "\n",
        "# Define your model configuration\n",
        "config_list_gemini = [\n",
        "    {\n",
        "        \"model\": gemini,\n",
        "        \"api_key\": api_key,\n",
        "        \"api_type\": \"google\"\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "# Initialize the assistant agent with the Gemini model configuration\n",
        "assistant = AssistantAgent(\n",
        "    name=\"assistant\",\n",
        "    llm_config={\n",
        "        \"cache_seed\": 41,\n",
        "        \"config_list\": config_list_gemini,\n",
        "        \"seed\": 42\n",
        "    },\n",
        ")\n",
        "\n",
        "# Initialize the user proxy agent\n",
        "try:\n",
        "  user_proxy = UserProxyAgent(\n",
        "    name=\"user_proxy\",\n",
        "    human_input_mode=\"NEVER\",\n",
        "    max_consecutive_auto_reply=MAX_USER_REPLIES,\n",
        "    is_termination_msg=lambda x: x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
        "    code_execution_config={\n",
        "        \"work_dir\": \"coding\",\n",
        "        \"use_docker\": False\n",
        "    },\n",
        "  )\n",
        "except Exception as e:\n",
        "  print(f\"The following error happened: {str(e)}\")\n",
        "  exit()\n",
        "\n",
        "\n",
        "# Start the chat between the user proxy and the assistant agent\n",
        "chat_response = user_proxy.initiate_chat(\n",
        "    assistant,\n",
        "    message=INPUT_START_MESSAGE,\n",
        "    # summary_method=\"reflection_with_llm\",\n",
        ")\n",
        "\n",
        "chat_id = chat_response.chat_id\n",
        "convs = chat_response.chat_history\n",
        "total_cost = chat_response.cost[1]\n",
        "\n",
        "print(f\"CHAT REF: {chat_id}\")\n",
        "print(f\"COST OF TRANSACTION: {total_cost}\")\n",
        "\n",
        "for conv in convs:\n",
        "  content = conv['content']\n",
        "  active_role = conv['role']\n",
        "\n",
        "  print(f\"{active_role}: {content}\")\n",
        "\n",
        "\n",
        "print(\"COMPLETE\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wX10KzyA6EnY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}