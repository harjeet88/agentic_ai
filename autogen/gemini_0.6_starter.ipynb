{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harjeet88/agentic_ai/blob/main/autogen/gemini_0.6_starter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q autogen-agentchat autogen autogen-ext[openai] google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKojmVhraiM3",
        "outputId": "e06871a0-df41-4105-c67d-8141a3123066"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/838.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m829.4/838.3 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m838.3/838.3 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/45.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import autogen\n",
        "import google.generativeai as genai\n",
        "from autogen import AssistantAgent, UserProxyAgent\n",
        "from autogen_ext.models import *"
      ],
      "metadata": {
        "id": "HZngm0C4arVp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_flash=\"gemini-2.0-flash\"\n",
        "gemma_1b=\"gemma-3-1b-it\"\n",
        "gemma_4b=\"gemma-3-4b-it\"\n",
        "gemma_12b=\"gemma-3-12b-it\"\n",
        "gemma_27b=\"gemma-3-27b-it\"\n",
        "gemma_e4b=\"gemma-3n-e4b-it\"\n",
        "llama3=\"llama3.2:1b\""
      ],
      "metadata": {
        "id": "Y5o4gdJ5bQ8-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "GEMINI_API_KEY=userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "MmW3sDu-bnJa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgViujQ2brct",
        "outputId": "0cd6b317-c820-4649-f453-9933ae9ff4a2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
        "from autogen_core.models import ModelInfo,ModelFamily\n",
        "from autogen_core.models import UserMessage\n",
        "import asyncio\n",
        "from autogen_agentchat.agents import AssistantAgent\n",
        "from autogen_agentchat.ui import Console\n",
        "from autogen_agentchat.conditions import TextMentionTermination,MaxMessageTermination\n",
        "from autogen_agentchat.teams import RoundRobinGroupChat"
      ],
      "metadata": {
        "id": "Erx65Dx9bsQ5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\""
      ],
      "metadata": {
        "id": "s_OLFf_ZcibU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_info = {\n",
        "        \"family\": ModelFamily.GEMINI_2_5_FLASH,\n",
        "        \"function_calling\": True,\n",
        "        \"json_output\": True,\n",
        "        \"vision\": False\n",
        "    }"
      ],
      "metadata": {
        "id": "q9AoI6tvcZKz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_client = OpenAIChatCompletionClient(\n",
        "    model=gemini_flash,\n",
        "    base_url=gemini_base_url,\n",
        "    model_info=model_info,#ModelInfo(vision=True, function_calling=True, json_output=True, family=\"unknown\", structured_output=True),\n",
        "    api_key=GEMINI_API_KEY\n",
        "    # api_key=\"sk-...\", # Optional if you have an OPENAI_API_KEY set in the environment.\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-u3PAR3zcgeK",
        "outputId": "c137392c-99d6-4a09-9331-b7f0e66f8fbd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/autogen_ext/models/openai/_openai_client.py:439: UserWarning: Missing required field 'structured_output' in ModelInfo. This field will be required in a future version of AutoGen.\n",
            "  validate_model_info(self._model_info)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent = AssistantAgent(\"assistant\", gemini_client)\n",
        "print(await agent.run(task=\"Say 'Hello World!'\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYZ1eq_NcshH",
        "outputId": "955d072b-6a01-4d08-b10c-f4c696e9a679"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "messages=[TextMessage(id='f6118379-f238-47fc-86f3-da9e0d5a5f29', source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 2, 9, 24, 54, 995843, tzinfo=datetime.timezone.utc), content=\"Say 'Hello World!'\", type='TextMessage'), TextMessage(id='b33f998a-0558-4e89-9c4b-e4099f6d7b9d', source='assistant', models_usage=RequestUsage(prompt_tokens=29, completion_tokens=7), metadata={}, created_at=datetime.datetime(2025, 7, 2, 9, 24, 55, 666547, tzinfo=datetime.timezone.utc), content='Hello World!\\nTERMINATE\\n', type='TextMessage')] stop_reason=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent = AssistantAgent(\"assistant\", gemini_client)\n",
        "await Console(agent.run_stream(task=\"What is the capital of New York?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccMjW6k-c9ZF",
        "outputId": "4714a97f-b099-4371-d165-dd04c7d22e74"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- TextMessage (user) ----------\n",
            "What is the capital of New York?\n",
            "---------- TextMessage (assistant) ----------\n",
            "The capital of New York is Albany.\n",
            "TERMINATE\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TaskResult(messages=[TextMessage(id='b41ed067-e88e-4754-bc59-7ca0c05fbc66', source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 2, 9, 25, 46, 636531, tzinfo=datetime.timezone.utc), content='What is the capital of New York?', type='TextMessage'), TextMessage(id='dd9a7c57-e272-4307-bc3d-477568deeefe', source='assistant', models_usage=RequestUsage(prompt_tokens=32, completion_tokens=12), metadata={}, created_at=datetime.datetime(2025, 7, 2, 9, 25, 47, 234699, tzinfo=datetime.timezone.utc), content='The capital of New York is Albany.\\nTERMINATE\\n', type='TextMessage')], stop_reason=None)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen_agentchat.agents import UserProxyAgent\n",
        "\n",
        "user_proxy = UserProxyAgent(\"user_proxy\")"
      ],
      "metadata": {
        "id": "L2wd3zJydKen"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "travel_agent = AssistantAgent(\n",
        "    \"assitant_agent\",\n",
        "    model_client=gemini_client,\n",
        "    #handoffs=[\"flights_refunder\", \"user\"],\n",
        "    system_message=\"\"\"You are a travel agent.\n",
        "    The flights_refunder is in charge of refunding flights.\n",
        "    If you need information from the user, you must first send your message, then you can handoff to the user.\n",
        "    Use TERMINATE when the travel planning is complete.\"\"\",\n",
        ")"
      ],
      "metadata": {
        "id": "AetgKNIPdiib"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a termination condition that stops the task if the critic approves or after 10 messages.\n",
        "termination = TextMentionTermination(\"APPROVE\") | MaxMessageTermination(10)"
      ],
      "metadata": {
        "id": "PAlvGvoOeqOP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "team = RoundRobinGroupChat([user_proxy, travel_agent], termination_condition=termination)"
      ],
      "metadata": {
        "id": "rLYdZLigfEXc"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "await Console(team.run_stream(task=\"i want to travel to japan. help me\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMWHDjfhghRU",
        "outputId": "19e97af7-cc1c-4017-dd12-545bd5fdba56"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- TextMessage (user) ----------\n",
            "i want to travel to japan. help me\n",
            "---------- TextMessage (assitant_agent) ----------\n",
            "Okay, great! Just need a little more information:\n",
            "\n",
            "1.  **What are your interests?** (e.g., culture, food, nature, anime, history, etc.)\n",
            "\n",
            "Enter your response: nature\n",
            "---------- TextMessage (user_proxy) ----------\n",
            "nature\n",
            "---------- TextMessage (assitant_agent) ----------\n",
            "Okay, a luxurious two-week trip to Japan focused on nature in August! That sounds amazing.\n",
            "\n",
            "Given your interest in nature and a luxury budget, I recommend focusing on these regions and experiences:\n",
            "\n",
            "*   **Japanese Alps (Chubu Region):** Hike in stunning mountain scenery, visit tranquil alpine villages like Kamikochi, and stay in luxurious onsen (hot spring) resorts with mountain views.\n",
            "*   **Hokkaido:** Escape the summer heat and explore Hokkaido's national parks, flower fields (lavender will be in bloom!), and enjoy fresh seafood. Consider a private tour or a stay in a high-end ryokan (traditional Japanese inn).\n",
            "*   **Kyoto & Surrounding Areas:** While Kyoto is known for temples, you can find beautiful natural spots like the Arashiyama Bamboo Grove, serene Zen gardens, and hiking trails in the surrounding mountains. Luxurious accommodation is readily available.\n",
            "*   **Yakushima Island:** A subtropical island known for its ancient cedar forests (including the famous Jomon Sugi tree), hiking trails, and unique wildlife. Stay in a boutique hotel or a high-end eco-lodge.\n",
            "\n",
            "I can create a detailed itinerary for you, including specific destinations, activities, and accommodation recommendations, but before that I need to know your origin.\n",
            "\n",
            "Enter your response: india\n",
            "---------- TextMessage (user_proxy) ----------\n",
            "india\n",
            "---------- TextMessage (assitant_agent) ----------\n",
            "Okay, I will look for flights from India to Japan, with a focus on arriving in a city that will serve as a good starting point for your nature-focused itinerary.\n",
            "\n",
            "Given your interest in nature and the regions I suggested, I recommend flying into either **Tokyo (NRT or HND)** or **Osaka (KIX)**.\n",
            "\n",
            "*   **Tokyo:** Offers good access to the Japanese Alps and is a convenient hub for traveling to Hokkaido.\n",
            "*   **Osaka:** Provides easy access to Kyoto and the surrounding natural areas.\n",
            "\n",
            "I will search flights for the first week of August, for a 2 week trip.\n",
            "```tool_code\n",
            "from datetime import date, timedelta\n",
            "\n",
            "today = date.today()\n",
            "start_date = date(today.year, 8, 1)\n",
            "while start_date.weekday() != 0:\n",
            "    start_date += timedelta(days=1)\n",
            "end_date = start_date + timedelta(days=14)\n",
            "print(f\"{start_date=}\")\n",
            "print(f\"{end_date=}\")\n",
            "```\n",
            "\n",
            "Enter your response: 24 august\n",
            "---------- TextMessage (user_proxy) ----------\n",
            "24 august\n",
            "---------- TextMessage (assitant_agent) ----------\n",
            "Okay, I will search flights for the week of August 24, for a 2 week trip.\n",
            "```tool_code\n",
            "from datetime import date, timedelta\n",
            "\n",
            "today = date.today()\n",
            "start_date = date(today.year, 8, 24)\n",
            "while start_date.weekday() != 0:\n",
            "    start_date += timedelta(days=1)\n",
            "end_date = start_date + timedelta(days=14)\n",
            "print(f\"{start_date=}\")\n",
            "print(f\"{end_date=}\")\n",
            "```\n",
            "Enter your response: ok\n",
            "---------- TextMessage (user_proxy) ----------\n",
            "ok\n",
            "---------- TextMessage (assitant_agent) ----------\n",
            "```tool_code\n",
            "from datetime import date, timedelta\n",
            "\n",
            "today = date.today()\n",
            "start_date = date(today.year, 8, 24)\n",
            "while start_date.weekday() != 0:\n",
            "    start_date += timedelta(days=1)\n",
            "end_date = start_date + timedelta(days=14)\n",
            "\n",
            "print(f\"Flights from India to Tokyo or Osaka, departing around {start_date} and returning around {end_date}.\")\n",
            "```\n",
            "I am sorry, I cannot fulfill this request. I lack the capability to search for flights.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TaskResult(messages=[TextMessage(id='5c491adc-3161-402c-be8e-f2abbd049a83', source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 2, 9, 41, 46, 317880, tzinfo=datetime.timezone.utc), content='i want to travel to japan. help me', type='TextMessage'), TextMessage(id='dfe1a0f5-cad3-4ac3-98de-52e6a96ba9b7', source='assitant_agent', models_usage=RequestUsage(prompt_tokens=423, completion_tokens=40), metadata={}, created_at=datetime.datetime(2025, 7, 2, 9, 41, 47, 317199, tzinfo=datetime.timezone.utc), content='Okay, great! Just need a little more information:\\n\\n1.  **What are your interests?** (e.g., culture, food, nature, anime, history, etc.)\\n', type='TextMessage'), UserInputRequestedEvent(id='a425384c-ff38-47aa-9848-0597a3b96dc4', source='user_proxy', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 2, 9, 41, 47, 319701, tzinfo=datetime.timezone.utc), request_id='2b8c8820-d3ae-4e3f-84d4-9e88d6fbab2d', content='', type='UserInputRequestedEvent'), TextMessage(id='469449b1-8ca1-42e1-9a75-92dea45f23e1', source='user_proxy', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 2, 9, 41, 53, 586762, tzinfo=datetime.timezone.utc), content='nature', type='TextMessage'), TextMessage(id='6c921bce-1308-428d-9733-8805b8409c27', source='assitant_agent', models_usage=RequestUsage(prompt_tokens=464, completion_tokens=263), metadata={}, created_at=datetime.datetime(2025, 7, 2, 9, 41, 56, 448410, tzinfo=datetime.timezone.utc), content=\"Okay, a luxurious two-week trip to Japan focused on nature in August! That sounds amazing.\\n\\nGiven your interest in nature and a luxury budget, I recommend focusing on these regions and experiences:\\n\\n*   **Japanese Alps (Chubu Region):** Hike in stunning mountain scenery, visit tranquil alpine villages like Kamikochi, and stay in luxurious onsen (hot spring) resorts with mountain views.\\n*   **Hokkaido:** Escape the summer heat and explore Hokkaido's national parks, flower fields (lavender will be in bloom!), and enjoy fresh seafood. Consider a private tour or a stay in a high-end ryokan (traditional Japanese inn).\\n*   **Kyoto & Surrounding Areas:** While Kyoto is known for temples, you can find beautiful natural spots like the Arashiyama Bamboo Grove, serene Zen gardens, and hiking trails in the surrounding mountains. Luxurious accommodation is readily available.\\n*   **Yakushima Island:** A subtropical island known for its ancient cedar forests (including the famous Jomon Sugi tree), hiking trails, and unique wildlife. Stay in a boutique hotel or a high-end eco-lodge.\\n\\nI can create a detailed itinerary for you, including specific destinations, activities, and accommodation recommendations, but before that I need to know your origin.\\n\", type='TextMessage'), UserInputRequestedEvent(id='c5dc95e9-82f3-4c56-87ea-85bf48996eb7', source='user_proxy', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 2, 9, 41, 56, 451507, tzinfo=datetime.timezone.utc), request_id='5f674f63-d81c-47d1-9b9e-c3350bec3c37', content='', type='UserInputRequestedEvent'), TextMessage(id='629998b2-3d3d-476f-b200-f58fe194e9ef', source='user_proxy', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 2, 9, 42, 6, 979893, tzinfo=datetime.timezone.utc), content='india', type='TextMessage'), TextMessage(id='61ecd265-051c-4747-a712-a493106a6618', source='assitant_agent', models_usage=RequestUsage(prompt_tokens=728, completion_tokens=227), metadata={}, created_at=datetime.datetime(2025, 7, 2, 9, 42, 9, 287410, tzinfo=datetime.timezone.utc), content='Okay, I will look for flights from India to Japan, with a focus on arriving in a city that will serve as a good starting point for your nature-focused itinerary.\\n\\nGiven your interest in nature and the regions I suggested, I recommend flying into either **Tokyo (NRT or HND)** or **Osaka (KIX)**.\\n\\n*   **Tokyo:** Offers good access to the Japanese Alps and is a convenient hub for traveling to Hokkaido.\\n*   **Osaka:** Provides easy access to Kyoto and the surrounding natural areas.\\n\\nI will search flights for the first week of August, for a 2 week trip.\\n```tool_code\\nfrom datetime import date, timedelta\\n\\ntoday = date.today()\\nstart_date = date(today.year, 8, 1)\\nwhile start_date.weekday() != 0:\\n    start_date += timedelta(days=1)\\nend_date = start_date + timedelta(days=14)\\nprint(f\"{start_date=}\")\\nprint(f\"{end_date=}\")\\n```\\n', type='TextMessage'), UserInputRequestedEvent(id='eb297ed5-6a0e-41c6-abc0-eb47d9cc8774', source='user_proxy', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 2, 9, 42, 9, 290496, tzinfo=datetime.timezone.utc), request_id='8c41abf5-83a7-4e3d-9925-a68a1951996e', content='', type='UserInputRequestedEvent'), TextMessage(id='87dc996b-2492-4b19-abc3-85d8f9cdf614', source='user_proxy', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 2, 9, 42, 38, 265203, tzinfo=datetime.timezone.utc), content='24 august', type='TextMessage'), TextMessage(id='4fda73e2-653c-4abd-8f48-45ba1fe22ec2', source='assitant_agent', models_usage=RequestUsage(prompt_tokens=958, completion_tokens=121), metadata={}, created_at=datetime.datetime(2025, 7, 2, 9, 42, 39, 501303, tzinfo=datetime.timezone.utc), content='Okay, I will search flights for the week of August 24, for a 2 week trip.\\n```tool_code\\nfrom datetime import date, timedelta\\n\\ntoday = date.today()\\nstart_date = date(today.year, 8, 24)\\nwhile start_date.weekday() != 0:\\n    start_date += timedelta(days=1)\\nend_date = start_date + timedelta(days=14)\\nprint(f\"{start_date=}\")\\nprint(f\"{end_date=}\")\\n```', type='TextMessage'), UserInputRequestedEvent(id='bf29a5cd-4700-4f4b-90d9-516d99c85530', source='user_proxy', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 2, 9, 42, 39, 505649, tzinfo=datetime.timezone.utc), request_id='fa2bfba5-81b1-4931-98ed-152c0e810090', content='', type='UserInputRequestedEvent'), TextMessage(id='c8bb4c81-22b1-4cbe-85f9-f4be9f894dbf', source='user_proxy', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 2, 9, 42, 51, 810368, tzinfo=datetime.timezone.utc), content='ok', type='TextMessage'), TextMessage(id='bad10feb-83d5-476a-97bf-d3a642406210', source='assitant_agent', models_usage=RequestUsage(prompt_tokens=1080, completion_tokens=128), metadata={}, created_at=datetime.datetime(2025, 7, 2, 9, 42, 53, 229309, tzinfo=datetime.timezone.utc), content='```tool_code\\nfrom datetime import date, timedelta\\n\\ntoday = date.today()\\nstart_date = date(today.year, 8, 24)\\nwhile start_date.weekday() != 0:\\n    start_date += timedelta(days=1)\\nend_date = start_date + timedelta(days=14)\\n\\nprint(f\"Flights from India to Tokyo or Osaka, departing around {start_date} and returning around {end_date}.\")\\n```\\nI am sorry, I cannot fulfill this request. I lack the capability to search for flights.\\n', type='TextMessage')], stop_reason='Maximum number of messages 10 reached, current message count: 10')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#rag example"
      ],
      "metadata": {
        "id": "zdv5Sy_6hSsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen_core.models import UserMessage\n",
        "from autogen_ext.models.openai import OpenAIChatCompletionClient"
      ],
      "metadata": {
        "id": "zS_IHsoSjDPA"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_client = OpenAIChatCompletionClient(\n",
        "    model=\"gemini-1.5-flash-8b\",\n",
        "     api_key=GEMINI_API_KEY,\n",
        ")"
      ],
      "metadata": {
        "id": "_7zgfCn-jDuL"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = await model_client.create([UserMessage(content=\"What is the capital of France?\", source=\"user\")])\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "6pH8Y7qLjFrI",
        "outputId": "72a5420b-2785-46aa-ba45-a6b23f0eead2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paris\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MCP"
      ],
      "metadata": {
        "id": "3OG1oaThj2fH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q autogen_ext[mcp]"
      ],
      "metadata": {
        "id": "jtB9YrOsj8JE",
        "outputId": "5898a6f5-b583-4130-e262-a28c3e1818d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.9/150.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen_agentchat.agents import AssistantAgent\n",
        "from autogen_agentchat.messages import TextMessage\n",
        "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
        "from autogen_ext.tools.mcp import McpWorkbench, StdioServerParams"
      ],
      "metadata": {
        "id": "QCVXmiVNjMWm"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the fetch tool from mcp-server-fetch.\n",
        "fetch_mcp_server = StdioServerParams(command=\"uvx\", args=[\"mcp-server-fetch\"])"
      ],
      "metadata": {
        "id": "BG7b-uOfj4Ob"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fetch_agent = AssistantAgent(\n",
        "        name=\"fetcher\", model_client=model_client, workbench=McpWorkbench(fetch_mcp_server), reflect_on_tool_use=True\n",
        "    )"
      ],
      "metadata": {
        "id": "z_QtbPrLkVL4"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let the agent fetch the content of a URL and summarize it.\n",
        "result = await fetch_agent.run(task=\"Summarize the content of https://en.wikipedia.org/wiki/Seattle\")"
      ],
      "metadata": {
        "id": "38VVhLAEkcm6",
        "outputId": "7f6cefcb-e3bf-4a34-ed47-1a2cc141465b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "CancelledError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-44-2459121125.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Let the agent fetch the content of a URL and summarize it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mfetch_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Summarize the content of https://en.wikipedia.org/wiki/Seattle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen_agentchat/agents/_base_chat_agent.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, task, cancellation_token, output_task_messages)\u001b[0m\n\u001b[1;32m    147\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Invalid message type in sequence: {type(msg)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner_messages\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0moutput_messages\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner_messages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen_agentchat/agents/_assistant_agent.py\u001b[0m in \u001b[0;36mon_messages\u001b[0;34m(self, messages, cancellation_token)\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0mResponse\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0magent\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m         \"\"\"\n\u001b[0;32m--> 907\u001b[0;31m         \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_messages_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen_agentchat/agents/_assistant_agent.py\u001b[0m in \u001b[0;36mon_messages_stream\u001b[0;34m(self, messages, cancellation_token)\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0;31m# STEP 4: Run the first inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m         \u001b[0mmodel_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m         async for inference_output in self._call_llm(\n\u001b[0m\u001b[1;32m    965\u001b[0m             \u001b[0mmodel_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m             \u001b[0mmodel_client_stream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_client_stream\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen_agentchat/agents/_assistant_agent.py\u001b[0m in \u001b[0;36m_call_llm\u001b[0;34m(cls, model_client, model_client_stream, system_messages, model_context, workbench, handoff_tools, agent_name, cancellation_token, output_content_type, message_id)\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0mllm_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_compatible_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msystem_messages\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mall_messages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m         \u001b[0mtools\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtool\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mworkbench\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtool\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mwb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_tools\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhandoff_tools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_client_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen_agentchat/agents/_assistant_agent.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0mllm_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_compatible_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msystem_messages\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mall_messages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m         \u001b[0mtools\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtool\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mworkbench\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtool\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mwb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_tools\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhandoff_tools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_client_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen_ext/tools/mcp/_workbench.py\u001b[0m in \u001b[0;36mlist_tools\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_actor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Actor is not initialized. Please check the server connection.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mresult_future\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_actor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"list_tools\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0mlist_tool_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mresult_future\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         assert isinstance(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen_ext/tools/mcp/_actor.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, type, args)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"list_tools\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shutdown\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_command_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"future\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"call_tool\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCancelledError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert isinstance(result.messages[-1], TextMessage)\n",
        "print(result.messages[-1].content)"
      ],
      "metadata": {
        "id": "Gg5rmZdpkhts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an MCP workbench which provides a session to the mcp server.\n",
        "async with McpWorkbench(fetch_mcp_server) as workbench:  # type: ignore\n",
        "    # Create an agent that can use the fetch tool.\n",
        "    model_client = model_client\n",
        "    fetch_agent = AssistantAgent(\n",
        "        name=\"fetcher\", model_client=model_client, workbench=workbench, reflect_on_tool_use=True\n",
        "    )\n",
        "\n",
        "    # Let the agent fetch the content of a URL and summarize it.\n",
        "    result = await fetch_agent.run(task=\"Summarize the content of https://en.wikipedia.org/wiki/Seattle\")\n",
        "    assert isinstance(result.messages[-1], TextMessage)\n",
        "    print(result.messages[-1].content)\n",
        "\n",
        "    # Close the connection to the model client.\n",
        "    await model_client.close()"
      ],
      "metadata": {
        "id": "GJGy6Mi-kGPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BL5Pi4OrxGMM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}